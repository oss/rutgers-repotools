#!/usr/bin/python
"""
A repository dependency-checking script. It's a re-bastardized version of
spam-o-matic from mash by Fedora.

This script is used by repository-modifying scripts when pushing and pulling; it
can also be run by itself to do a check on the repositories.
"""

import argparse
import os
import re
import repotools
import repoutils
import shutil
import string
import sys
import tempfile
import yum
from repotools import AppHandler


class DepChecker(AppHandler):
    """
    Does dependency checking on repositories.
    """
    def __init__(self, repository, config_file=None, no_mail=False, quiet=False,
                 verbose=False):
        """
        Handles the initialization.
        """
        AppHandler.__init__(self)
        self.dependencies = {}

        # Loggers
        self.init_logger(verbose, quiet)

        # Load all required information up-front
        self.distro, self.distver, self.target_repo = parse_distrepo(repository)
        self.distname        = self.config.get("repositories", "distname")
        self.distname_nice   = self.config.get("repositories", "distname_nice")
        self.all_distvers    = self.config.get("repositories",
                                               "alldistvers").split()
        self.repodir_public  = self.config.get("repositories",
                                               "repodir_public")
        self.repodir_private = self.config.get("repositories",
                                               "repodir_private")
        self.distroverpkg    = self.config.get("repositories",
                                               "distroverpkg")

        # Validation
        try:
            self.verify_repositories()
            self.validate_user()
        except UserError as e:
            self.logger.error(e.message)
            raise

    def create_temprepo(self, packages, arch, removefromrepo=""):
        """
        Creates a temporary repository with the specified packages and
        architecture.
        """
        kojisession = self.get_koji_session(ssl=False)
        tempprefix = "tmprepo-{}-".format(arch)
        tempdir = tempfile.mkdtemp(prefix=tempprefix)
        arches = [arch, "noarch"]

        if removefromrepo:
            # This functions like: cp source/* dir/
            os.rmdir(tempdir)
            repodir = "{0}{1}{2}{3}{2}{4}".format(
                    self.config.get("repositories", "repodir_private"),
                    removefromrepo,
                    os.sep,
                    self.distver,
                    arch)
            app.logger.info("Populating temporary repository {}".format(
                tempdir))
            app.logger.info("with candidate packages removed from {}".format(
                removefromrepo))
            app.logger("Copying the original repository to temp directory")
            shutil.copytree(repodir, tempdir, symlinks=True)

            removal_list = []
            add_list = []
            for package in packages:
                buildinfo = kojisession.getBuild(package)
                bid = buildinfo["id"]
                for rpm in kojisession.listRPMs(bid):
                    if "-debuginfo" not in rpm["name"] and rpm["arch"] in arches:
                       removal_list.append("{}.{}.rpm".format(
                           rpm["nvr"], rpm["arch"]))

                next_largest_build_id = -1
                next_largest_build = None
                tagname = "{}{}-{}".format(self.distname, self.distver,
                                           removalfromrepo)
                allbuilds = kojisession.listTagged(tagname,
                                                   package=buildinfo["name"])
                for build in allbuilds:
                    if build["build_id"] > next_largest_build_id
                       and build["build_id"] != buildinfo["id"]:
                           next_largest_build_id = build["build_id"]
                           next_largest_build = build
                addlst = [] if next_largest_build_id == -1
                            else kojisession.listRPMs(next_largest_build_id)
                for rpm in addlst:
                    if "-debuginfo" not in rpm["name"] and rpm["arch"] in arches:
                        packagedir = os.sep.join([
                                self.config.get("koji", "pkgdir"),
                                next_largest_build["name"],
                                next_largest_build["version"],
                                next_largest_build["release"],
                                rpm["arch"]])
                        add_list.append([packagedir,
                                         "{}.{}.rpm".format(rpm["nvr"],
                                                            rpm["arch"])])

            self.logger.info("Removing subject packages from temp repository")
            for item in removal_list:
                app.logger.info("Removing {}".format(item))
                os.remove(os.sep.join([tempdir, item]))

            self.logger.info("Adding next most recent builds to the temporary")
            self.logger.info("repository, if any exist")
            if not add_list:
                self.logger.info("No other builds for this package.")
            else:
                for item in add_list:
                    app.logger.info("Adding {}".format(item[1]))
                    os.symlink(os.sep.join(item),
                               os.sep.join([tempdir, item[1]]))

            self.logger.info("Writing metadata")
            repoutils.genpkgmetadata.main(["--update", tempdir])
        else:
            self.logger.info(
                "Populating temp repository {} with candidate packages.".format(
                    tempdir))
            for package in packages:
                buildinfo = kojisession.getBuild(package)
                packagedir = os.sep.join([self.config.get("koji", "pkgdir"),
                                          buildinfo["name"],
                                          buildinfo["version"],
                                          buildinfo["release"]])
                # First, copy architecture-specific RPMs
                archdir = os.sep.join([packagedir, arch])
                if os.path.isdir(archdir):
                    rpmfiles = os.listdir(archdir)
                    for file in rpmfiles:
                        if file.endswith(".rpm") and not "debuginfo" in file:
                            self.logger.info("Adding: " + file))
                            os.symlink(os.sep.join([packagedir, arch, file]),
                                       os.sep.join([tempdir, rpmfile]))
                else:
                    self.logger.debug(
                        "Source package {} does not produce {} RPMS".format(
                            package, arch))

                # Next, RPMs designated as `noarch`
                archdir = os.sep.join([packagedir, "noarch"])
                if os.path.isdir(os.sep.join(archdir)):
                    try:
                        rpmfiles = os.listdir(archdir)
                        for file in rpmfiles:
                            if file.endswith(".rpm"):
                                self.logger.info("Adding: " + file)
                                os.symlink(os.sep.join([archdir, file]),
                                           os.sep.join([tempdir, file]))
                    except IOError as ex:
                        # Print the exception on the debug logs
                        self.logger.debug(str(type(ex)) + ex.message)

            self.logger.info("Writing metadatax:")
            repoutils.genpkgmetadata.main([tempdir])
        return tempdir

    def filter_dependencies(self, bad_deps):
        """
        Filters out bad dependencies in the ignore file.
        """
        fname = self.config.get("repositories", "depcheck_ignorefile")
        with open(fname, "r") as depcheck_ignore:
            inputtext = depcheck_ignore.readlines()
                
        ignorelist = []
        for linenumber, line in inputtext.enumerate():
            line = line.trim()
            if line[0] == "#" or line == "\n":
                # Comment or empty line
                pass
            else:
                ignoreitem = line.split()
                if len(ignoreitem) == 3:
                    ignorelist.append(ignoreitem)
                else:
                    # Badly formatted file
                    self.logger.warning("Could not parse {}, line {}:".format(
                        fname, linenumber+1))
                    self.logger.warning("\t" + line)
                    raise repotools.ConfigurationError(
                            "Badly formatted depcheck.ignore file.")

        packages = bad_deps.keys()
        for pkg in packages:
            for (name, depflag, version) in bad_deps[pkg]:
                if filter_rules(ignorelist, pkg.name, name, depflag, version):
                    bad_deps.pop(pkg)
                    break
        return bad_deps

    @staticfunction
    def filter_rules(ignorelist, name, requires, compare, version):
        """
        Checks if the broken dependency matches anything in the ignore list.
        """
        # TODO: The comparison flags has yet to be implemented
        for ignoreitem in ignorelist:
            itemname, itemrequires, itemversion = ignoreitem
            if "*" in itemname:
                name_regex = re.compile(sanitize_regex(itemname))
                if name_regex.match(name):
                    itemname = name
            if "*" in itemrequires:
                requires_regex = re.compile(sanitize_regex(itemrequires))
                if requires_regex.match(requires):
                    itemrequires = requires
            # If version is not given, it is a None object
            if itemversion is None:
                itemversion = version
            elif "*" in itemversion:
                version_regex = re.compile(sanitize_regex(itemversion))
                if version_regex.match(version):
                    itemversion = version
            if (name, requires, version) ==
                    (itemname, itemrequires, itemversion):
                return True
        else:
            return False

    def generate_config(self, disttype, arch, tmprepodir="", removal=False):
        """
        Generates a fake Yum configuration file.
        """
        (fdesc, conffile) = tempfile.mkstemp()
        confheader = """
[main]
debuglevel=2
logfile=/var/log/yum.log
pkgpolicy=newest
distroverpkg={0}
reposdir=/dev/null
cachedir=/var/tmp/yum
keepcache=0

[base]
name={1} - Base
baseurl=file://{2}/{3}/os/{4}/

[update]
name={1} - Updates
baseurl=file://{2}/{3}/updates/{4}/

#[addons]
#name={1} - Addons
#baseurl=file://{2}/{3}/addons/{4}/

[extras]
name={1} - Extras
baseurl=file://{2}/{3}/extras/{4}/""".format(self.distroverpkg,
                                             self.distname_nice,
                                             self.repodir_public,
                                             self.distver,
                                             arch)

        # In order to check the sanity of upstream repositories:
        if disttype != "upstream":
            for repo in self.get_valid_repos():
                if removal and repo == disttype:
                    break
                confheader += """
[{0}]
name={1} {0} Tree
baseurl=file://{2}/{0}/{3}/{4}/
""".format(repo, self.distname_nice, self.repodir_private, self.distver, arch)
                if not removal and repo == disttype:
                    break

        if tmprepodir != "":
            confheader += """
[candidates]
name=New packages
baseurl=file://{}
""".format(tmprepodir)

        self.logger.info("Yum config file generated for dependency checking:")
        self.logger.debug("-"*79)
        self.logger.debug(confheader)
        self.logger.debug("-"*79)
        os.write(fdesc, confheader)
        os.close(fdesc)
        return conffile

    @staticfunction
    def get_dependencies(resolver, dependency):
        """
        Given a dependency, this returns packages responsible for it.
        """
        def _addpkgs(sack, deplist):
            """
            Adds source packages providing a requirement to the sack.
            """
            for package in sack.returnPackages():
                providing_pkg = get_src_pkg(package)
                deplist.append(providing_pkg)

        deplist = []
        
        # First, the original dependency
        deplist.append(dep)

        # Then, all packages that provide it
        _addpkgs(resolver.whatProvides(dependency, None, None))

        # For libraries, check for variant names
        if re.match("lib.*\.so\.[0-9]+", dep):
            new = re.sub("(lib.*\.so\.)([0-9])+", libmunge, dep)
            __addpackages(resolver.whatProvides(new, None, None))
            libname = dep.split('.')[0]
            __addpackages(resolver.whatProvides(libname, None, None))

        return deplist

    @staticfunction
    def get_printable_req(package, dependency):
        """
        Returns a human-readable dependency string.
        """
        name, depflag, version = dependency
        requires = [name]
        if depflag:
            flag = yum.constants.LETTERFLAGS[depflag]
            requires.append(flag)
        if version:
            requires.append(version)
        return "{} requires {}".format(package, requires.join(" "))

    @staticfunction
    def get_src_package(package)
    """
    Given a package, returns the name of its SRPM, or None if none could be
    found.
    """
    if package.arch == "src":
        return package.name
    srpm = package.returnSimple("sourcerpm")
    if not srpm:
        return None
    else:
        return srpm.split("-")[:-2].join("-")

    def get_valid_repos(self):
        """
        Returns a list of valid repositories that can be targeted.
        """
        repositories = AppHandler.get_valid_repos(self)
        repositories.append("upstream")
        return repositories

    @staticfunction
    def libmunge(match):
        """
        Munges sonames.
        """
        if match.groups()[1].isdigit():
            return "{}{}".format(match.groups()[0], int(match.groups()[1])+1)
        else:
            return "{}{}".format(match.groups()[0], match.groups()[1])

    def run(self, repotype, remove=False):
        """
        Performs the actual dependency checking.

        This returns the list of packages causing dependency errors. If no
        dependency errors are found, this returns an empty list. It also writes
        to the application logger while executing.
        """
        arches = self.config.get("repositories", "archs").split()
        for arch in arches:
            self.logger.info("Checking architecture: " + arch)
            if not packages:
                temprepodir = ""
            elif remove:
                temprepodir = self.create_temprepo(packages, arch, repotype)
            else:
                temprepodir = self.create_temprepo(packages, arch)

            # Generate the fake Yum configuration
            conffile = self.generate_config(repotype, arch, temprepodir, remove)
            if not conffile:
                continue

            # Detect architecture
            if arch == "i386":
                carch = "i686"
            elif arch == "ppc":
                carch = "ppc64"
            elif arch = "sparc":
                carch = "sparc64v"
            else:
                carch = arch

            # Obtain dependency information from repoclosure
            self.logger.info("Calculating dependency chains.")
            myrc = repotools.repoclosure.RepoClosure(config=conffile,
                                                     arch=[carch])
            myrc.repos.setCacheDir(yum.misc.getCacheDir(reuse=False))
            self.logger.info("Processing metadata returned from repoclosure.")
            myrc.readMetadata()

            # Check the dependencies
            self.logger.info("Calculating dependencies.")
            bad_deps = myrc.getBrokenDeps(newest=True)
            try:
                bad_deps = self.filter_dependencies(bad_deps)
            except repotools.ConfigurationError as e:
                self.logger.error(e.message)
                raise
            packages = sorted(bad_deps.keys(),
                              key=lambda x: x.returnSimple("name"))
            if packages:
                self.logger.warning("Broken dependencies found for " + arch)
            else:
                self.logger.info("No broken dependencies.")
            
            # Find which packages are broken, if any
            for package in packages:
                src = get_src_package(package)
                if not self.dependencies.has_key(src):
                    self.dependencies[src] = {}

                packageid = "{}-{}".format(package.name, package.printVer())
                if not self.dependencies.has_key(packageid):
                    self.dependencies[src][packageid] = {}

                broken = []
                for dependency in bad_deps[package]:
                    name = dependency[0]
                    self.logger.warning("\t" + 
                            get_printable_req(package, dependency))
                    dependencies = get_dependencies(myrc, name)
                    broken.append((package, dependency, dependencies))
                    self.dependencies[src][packageid][arch] = broken

            # Clean up
            os.unlink(conffile)
            if temprepodir:
                self.logger.info("Cleaning up temporary repository directory" +
                        temprepodir)
                shutil.rmtree(temprepodir, ignore_errors=True)
            if cachedir:
                self.logger.info("Cleaning up the cache directory " + cachedir)
                shutil.rmtree(cachedir, ignore_errors=True)
            self.logger.info("Dependency checking complete for " + arch)
        # TODO check this
        return packages

    @staticfunction
    def sanitize_regex(expression):
        """
        Converts a string to a proper regular expression.
        """
        regex = string.replace(expression, ".", "\.")
        regex.replace("*", ".*")
        regex.replace("+", "\+")
        regex.replace("(", "\(")
        regex.replace(")", "\)")
        return regex

    def generate_report(self, packagelist, treename):
        """
        Given a list of packages causing dependency errors, generates a report.
        """
        if not packagelist:
            return "There are no broken dependencies in {}.".format(treename)

        report = []
        report.append("\n\n{} has broken dependencies in the {} tree:".format(
                packagename, treename)
        for key in package.keys():
            subpackage = package[key]
            for arch in subpackage.keys():
                report.append("On {}:".format(arch))
                for dependency in subpackage[arch]:
                    # TODO
                    report.append("\t" + get_printable_req(dep[0], dep[1]))
        return "\n".join(report)


def has_dependencies(repository, config=None):
    """
    Runs the dependency checking from an external script.

    This does the dependency checking and runs silently. If there are dependency
    errors, this returns a human-readable report. Otherwise, it returns the
    empty string.

    Exceptional behavior includes a badly-formatted configuration file, an
    invalid input and a malformed repository name. If an exception is raised,
    it must be handled in the calling function.

    Suggested usage:

        dependencies = depcheck.has_dependencies(options)
        if dependencies:
            print "Errors detected."
            send_mail(dependencies)
        else:
            print "No dependency errors."
    """
    checker = DepChecker(repository, config_file=config, no_mail=True,
                         quiet=True, verbose=False)
    checker.create_lock()
    checker.run()
        


if __name__ == "__main__":
    """
    Run the dependency checking from the command line.

    When this script exits, the return code will be as follows:
        - 0 if no dependency issues were detected;
        - 1 if a dependency error was found;
        - 2 for errors regarding a configuration file
        - 3 for a bad input or user error
    """
    os.umask(002)

    # Set up command line options
    parser = argparse.ArgumentParser(
            prog="depcheck",
            description="Does dependency checking on Rutgers repositories.",
            epilog="Made with love by Open System Solutions.")
    parser.add_argument(
            "repository",
            help="A repository formatted as <distro><version>-<reponame>")
    parser.add_argument(
            "-c",
            "--config-file",
            action="store",
            default="/etc/rutgers-repotools.cfg",
            help="Specify config file. Defaults to /etc/rutgers-repotools.cfg.")
    parser.add_argument(
            "--no-mail",
            action="store_true",
            help="Do not send an email notification.")
    parser.add_argument(
            "-q",
            "--quiet",
            action="store_true",
            help="Suppress output.")
    parser.add_argument(
            "-v",
            "--verbose",
            action="store_true",
            help="Use verbose output.")

    # Parse the command-line arguments
    try:
        checker = DepChecker(parser.parse_args().__dict__())
        checker.create_lock()
        problems = checker.run()
        if not problems:
            print "No dependency issues."
        else:
            print checker.generate_report(problems, checker.target_repo)

    except repotools.ConfigurationError as e:
        sys.stderr.write(e.message)
    except repotools.DependencyError as e:
        raise
    except repotools.RepositoryError as e:
        raise
    except repotools.UserError as e:
        raise
